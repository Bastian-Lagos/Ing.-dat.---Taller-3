{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ffab67",
   "metadata": {},
   "source": [
    "## Generacion de CSV (Opcional)\n",
    "\n",
    "Primero ejecutamos el codigo para generar el archivo csv desde el cual se creara el dataframe, al modificar el valor de \"pages\" se pueden obtener mas o menos datos segun sea necesario. Es importante recalcar que esto solo funcionara si se tiene una RAWG_API_KEY para acceder a la API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d8d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos guardados en steam_sample2.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import app\n",
    "\n",
    "nombreArchivo = \"steam_sample.csv\"\n",
    "\n",
    "dfe = app.extract_data(pages=10)\n",
    "dfe.to_csv(\"../data/\"+nombreArchivo, index=False)\n",
    "print(\"Datos guardados en \"+nombreArchivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b9f9d",
   "metadata": {},
   "source": [
    "Primeramente haremos los imports necesarios y cargaremos el dataframe, mientras que asignamos lo que catalogaremos como \"exito\", lo cual serian puntuaciones \"buenas\" por RawG y Metacritic, y que hayan mas usuarios interesados que reseñas en RawG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2dfdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "df = pd.read_csv(\"../data/steam_sample.csv\")\n",
    "\n",
    "df[\"success\"] = (df[\"rating\"] >= 4) & (df[\"metacritic\"] >= 75) & (df[\"ratings_count\"] < df[\"usuarios_interesados\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9a8cf",
   "metadata": {},
   "source": [
    "Aqui vemos como quedaron los resultados de la clasificacion de juegos \"exitosos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22160a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "False    234\n",
      "True     166\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"success\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f6e48",
   "metadata": {},
   "source": [
    "Ahora entrenamos el modelo para que pueda predecir el \"exito\" de un juego basado en los generos del juego."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b83352",
   "metadata": {},
   "source": [
    "\n",
    "## División del conjunto de datos\n",
    "\n",
    "Se dividió el conjunto de datos en tres subconjuntos: entrenamiento (60%), validación (20%) y prueba (20%). \n",
    "Se utilizó la técnica de estratificación para asegurar que la proporción de clases se mantuviera constante en cada subconjunto, \n",
    "lo que es especialmente importante cuando se trabaja con clases desbalanceadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d62d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.821918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo  Accuracy  Precision    Recall  F1 Score\n",
       "0        Random Forest    0.8375   0.857143  0.789474  0.821918\n",
       "2  Logistic Regression    0.8125   0.870968  0.710526  0.782609\n",
       "1                  SVM    0.6750   0.730769  0.500000  0.593750"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_genres = MultiLabelBinarizer()\n",
    "genres_encoded = mlb_genres.fit_transform(df[\"generos\"].apply(eval))  # listas\n",
    "\n",
    "X = pd.DataFrame(genres_encoded, columns=mlb_genres.classes_)\n",
    "X[\"ratings_count\"] = df[\"ratings_count\"]\n",
    "X[\"metacritic\"] = df[\"metacritic\"].fillna(0)\n",
    "y = df[\"success\"]\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30c671",
   "metadata": {},
   "source": [
    "## Evaluacion de algoritmos de clasificacion\n",
    "\n",
    "En este segmento se probaran los algoritmos Random Forest, SVC y Logistic Regression, para analizar sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006fc2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    results.append({\n",
    "        \"Modelo\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results).sort_values(by=\"F1 Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bb14bf",
   "metadata": {},
   "source": [
    "Aqui hay un ejemplo para ver que predice el modelo con respecto al \"exito\" que tendra un juego basado en sus generos y la probabilidad de que se cumpla la prediccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58e00f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Será exitoso? True\n",
      "Probabilidad: 0.5408173516412131\n"
     ]
    }
   ],
   "source": [
    "def predecir_exito(generos, ratings_count=1000, metacritic=80):\n",
    "    input_data = pd.DataFrame([0]*len(mlb_genres.classes_), index=mlb_genres.classes_).T\n",
    "    for genre in generos:\n",
    "        if genre in input_data.columns:\n",
    "            input_data[genre] = 1\n",
    "    input_data[\"ratings_count\"] = ratings_count\n",
    "    input_data[\"metacritic\"] = metacritic\n",
    "\n",
    "    pred = model.predict(input_data)[0]\n",
    "    prob = model.predict_proba(input_data)[0][1]\n",
    "    return bool(pred), prob\n",
    "\n",
    "exito, probabilidad = predecir_exito([\"Family\"], ratings_count=500, metacritic=85)\n",
    "print(\"¿Será exitoso?\", exito)\n",
    "print(\"Probabilidad:\", probabilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8f261",
   "metadata": {},
   "source": [
    "## Selección y ajuste de hiperparámetros\n",
    "\n",
    "Se utilizó la técnica de Grid Search con validación cruzada (5-fold) para encontrar los mejores hiperparámetros del modelo Random Forest.\n",
    "Se evaluaron `n_estimators` y `max_depth` por su impacto directo en el sesgo y varianza del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15685739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b7e580",
   "metadata": {},
   "source": [
    "## Manejo de clases desbalanceadas\n",
    "\n",
    "Se detectó un desbalance en las clases, por lo tanto, se empleó la estrategia `class_weight='balanced'` en los modelos \n",
    "para ajustar los pesos inversamente proporcionales a la frecuencia de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "svm_model = SVC(class_weight='balanced', random_state=42)\n",
    "log_model = LogisticRegression(class_weight='balanced', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e77b3",
   "metadata": {},
   "source": [
    "## Métricas de evaluación\n",
    "\n",
    "Se evaluaron los modelos utilizando precisión, recall y F1-score, ya que este último es una medida armónica que balancea precisión y recall, \n",
    "lo cual es fundamental en contextos con clases desbalanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, X, y, label=\"Validación\"):\n",
    "    y_pred = model.predict(X)\n",
    "    print(f\"Evaluación en {label}:\")\n",
    "    print(\"Precisión:\", precision_score(y, y_pred))\n",
    "    print(\"Recall:\", recall_score(y, y_pred))\n",
    "    print(\"F1-score:\", f1_score(y, y_pred))\n",
    "\n",
    "evaluate_model(best_model, X_val, y_val, \"Validación\")\n",
    "evaluate_model(best_model, X_test, y_test, \"Prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943099ca",
   "metadata": {},
   "source": [
    "## Interpretación de resultados\n",
    "\n",
    "Se compararon los resultados de distintos modelos usando tablas para identificar sus fortalezas y debilidades. \n",
    "Esto permite observar cómo se desempeñan en métricas clave y tomar decisiones informadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c3de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": best_model,\n",
    "    \"SVM\": svm_model.fit(X_train, y_train),\n",
    "    \"Logistic Regression\": log_model.fit(X_train, y_train)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_val)\n",
    "    results.append({\n",
    "        \"Modelo\": name,\n",
    "        \"Precisión\": precision_score(y_val, y_pred),\n",
    "        \"Recall\": recall_score(y_val, y_pred),\n",
    "        \"F1-score\": f1_score(y_val, y_pred)\n",
    "    })\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d9d60",
   "metadata": {},
   "source": [
    "## Selección del modelo final\n",
    "\n",
    "Se seleccionó el modelo con el mayor F1-score como el más adecuado para el problema. Este criterio considera tanto \n",
    "la precisión como el recall, lo que es ideal cuando las clases están desbalanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d551e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = results_df.loc[results_df[\"F1-score\"].idxmax()]\n",
    "print(\"Modelo seleccionado:\", best_row[\"Modelo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aca338",
   "metadata": {},
   "source": [
    "## Reproducibilidad del experimento\n",
    "\n",
    "Para garantizar la reproducibilidad del experimento, se fijaron las semillas aleatorias y se recomienda mantener un entorno \n",
    "consistente mediante control de versiones y especificación de dependencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eda92a",
   "metadata": {},
   "source": [
    "## Uso de GPT\n",
    "\n",
    "A lo largo del desarrollo se utilizo ChatGPT para ayudar a consolidar la informacion dentro de las casillas de texto, asi como en la generacion de codigo, resultando al final en un archivo mezclado con las casillas hechas por nosotros y ChatGPT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
